* How to assess the performance of an algorithm?
:PROPERTIES:
:CUSTOM_ID: how-to-assess-the-performance-of-an-algorithm
:END:
- Most interested in the worst case analysis.
- Provides upper bound not specific to any particular input and can be
  considered a performance guarantee
- The performance T(n) isually chracteristed in terms of a singel free
  variable n corresponding to the input size
- What n describes exactly must be clear from the context (for example
  T(V), time processing Vertices)
- While most of the time we are analysing the running time of the
  algorithms, the same techniques can be used for other important
  resources like memory footprint
- IE the concept of the order of growth which considers very large
  instances where n can go up to infinity so that any fixed overhead
  costs become insignificant for the analysis. Ignores absolute units of
  time in favour of focusing on the general shape of how T(n) increases
  with increasing n ## Order of growth table:

![[Pasted image 20250514134801.png]]

** O-Notation - Worst case
:PROPERTIES:
:CUSTOM_ID: o-notation---worst-case
:END:
- The set of functions with an asymptotic upper bound setting on how
  slow your code can be:
  - O(g(n)) = 0 <= f(n) <= cg(n)
  - T(n) = an^2 +bn+c = O(n^2) - Worst case asymptotic run time of the
    insertion sort algorithm ### o Notation - loose upper bound of f(n)
- Little o is the loose upper-bound of a particular function, rough
  estimate of the maximum order of growth whereas Big o may be actual
  order of growth
- ð‘œ ð‘” ð‘› = ð‘“(ð‘›) âˆ€ð‘ âˆˆ â„+: âˆƒð‘›0 âˆˆ â„•: ð‘› â‰¥ ð‘›0 â‡’ 0 â‰¤ ð‘“ ð‘› < ð‘ð‘” ð‘›
- The bound must hold for *any* constant factor (not just some)

** Omega(Î©)-Notation - best case performance
:PROPERTIES:
:CUSTOM_ID: omegaÏ‰-notation---best-case-performance
:END:
- The set of functions with an asymptotic lower bound , the typical case
  performance for an algorithm:

  - Î©(g(n)) = 0 <= c(g(n)) <= f(n)
  - Best case for insertion sort is at least linear
    - T(n) = a n + b = Î©(n) ### Little omega (w) - loose lower bound of
      f(n)

- Little w notation is used to describe the relationship between two
  functions when one grows strictly faster than the other ie if f(n)=
  w(g(n)) thne g(n) grows slower than f(n) as n approaches infinity. ##
  Î˜-Notation - average case performance

- The set of functions with an asymptotic tight bound ie in the middle

- Î˜(g(n)) = c1g(n)<= f(n)<= c2(g(n))

- It is easy to see that Î˜ ð‘”(ð‘›) = ð‘‚ ð‘” ð‘› âˆ© Î© ð‘”(ð‘›) - In other words the
  funciton can only be denoted as teta g(n) if an only if f(n)= O(g(n))
  and f(n) = Î© (g(n))

- For insertion sort the worst case asymptotic runtime can be shown as
  omega(n^2) so that the asymptotic tight bound is:

  - T(n)=Î˜(n^2)

* Summary:
:PROPERTIES:
:CUSTOM_ID: summary
:END:
â€¢ The worst-case upper bound ð‘‚(ð‘› 2 ) is a maximum runtime guarantee for
all inputs â€¢ The worst-case tight bound Î˜ ð‘› 2 is more precise in also
guaranteeing that the worst-case *can* happen - *Average* â€¢ The
best-case lower bound Î©(ð‘›) is the minimum required runtime regardless of
the input ## Hierarchy of increasingly asymptotically larger functions:

![[Pasted image 20250514140946.png]]

*** Examples
:PROPERTIES:
:CUSTOM_ID: examples
:END:
**** Key notes
:PROPERTIES:
:CUSTOM_ID: key-notes
:END:
- Refer to hierarchy when deciding on notations - the largest growth
  order takes precedence
- Ignore constants such as 4n or 2nlogn - In real case scenarios roughly
  important but for measuring potential performance not really ###
  Example 1

1. 4n^2 + 2n + 3: n^2 +n : n^2 - Î˜(n^2) - Average case performance is
   tita n squared
2. 2n+4nlogn - n + nlogn = Average case performance is titanlogn
3. 3n^2 + 4nlogn = n^2 + nlogn = titan^2
4. 7logn + 3n +2 = tita(n)
5. 2n^3 - 6n - 5 = tita(n^3)

*** Example 2
:PROPERTIES:
:CUSTOM_ID: example-2
:END:
#+begin_src C
// Insertion sort
for j = 2..n{ // O(n)
    k = A[j] // O(n)*O(1)
    i = j-1 //  O(n)*O(1)
    while i> 0 && A[i] > k{ // O(n) * O(n) = O(n^2)
        A[i+1]  = A[i] // O(n^2)*O(1)
        i   = i-1 // O(n^2)*O(1)
    }
    A[i+1] = k O(n)*O(1)
}
#+end_src

- To derive our best/worst case here, we take all of the derived
  notations, sum them up so here it would be 4O(n) + 3O(n^2) = O(n) +
  O(n^2) as we ignore constants and then since O(n^2) has a higher order
  of growth compared to O(n), we take O(n^2) as our final order of
  growth answer
