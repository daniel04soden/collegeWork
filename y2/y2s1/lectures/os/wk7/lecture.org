#+title: IO File systems and devices

* IO Management

- Key issues are
  - Performance
  - Generality
  - Reliability
  - Security

    - Disk io is the most common form of io and disks are used to store databases, user file directories,
      virtual memory swap space etc.
    - Disk IO is orders of magnitude slower than processor access to main memory, for these reasons lots of work goes into trying to improve performance of disk IO

     - There are levels of organisation between user processes and the hardware
       User process
       Directory management
       File system
       Physical organisation
       Device IO
       Scheduling and control
       Hardware

** Levels of IO Organization

  - A user process requests IO from/to  a named file
    - Directory management: filenames converted into ID numbers for reference to the file and opeartions such as add delete and re-organisation
      of directories are handled

    - File system:
      - Programmer's logical operations such as open close read write are dealt with as well as permissions.

    - Physical organization: here programmers 
  
    - Device IO here the IO request details are converted into low level io instructions, channel commands and controller orders.

    - Scheduling and control: here IO requests are scheduled for access to the disk and device control instructions are executed.
      - Interrupts and IO status are dealt with here and this layer accesses the hardware through the IO module

     - Hardware: the actual physical disk signals make the physical drive 
** IO Evolution

- The components that make up the architecture of processors have over the years become more complex and specialized
  - We will summarize the evolution and specialization of the IO function over time

    1. Direct processor control of disk
    2. Addition of IO controller or module which hides the devices complexities from the main processor
       - No interrupt mechanism -> busy waiting (Processor will have to wait for IO)
    3. As stage 2 with addition of interrupt mechanisms
       - No busy waiting
         - Processor doesnt ahve to wait for IO >>> increases efficiency
    4. IO module given direct access to memory DMA. Main processor need not be disturbed
    5. IO module becomes separate processor with specialized IO instruction set and DMA. This allows main processor to delegate a sequence of IO operations.
    6. IO module has its own memory and takes care of host devices

** DMA

- Direct memory access or dma allows every device to have a queue of pending requests
  - An io request is issued by a process using a syscall to the OS to read/write a block of text


- The command to the IO module contains the following info:
  - Read write operation?
  - IO device address
  - Starting address of data in memory
  - Number of memory words to be read or written
 - The cpu can then be used for other work
 - Meanwhile the IO module uses DMA to transfer the data directly to/from memory
 - When the transfer is completed, the IO module interrupts the CPU

- DMA configs differ; a more efficient one is where interaction between DMA and devices is handled on a separate bus

*** Sharing the RAM

- The dma can only use the data bus when the CPU is not using it,
  so often the CPU will pause for one bus cycle and allow dma to access memory
  This is known as cycle stealing.
  This pausing slows the CPU but is preferable to interrupt handling

* IO Buffering
- The process request a a block of data
  - The process becomes locked and only restarts when the IO is complete.
- The os initiates the transfer of the data into main memory

  - This is inefficient as:
    - the process is blocked waiting for IO
      - The os cannot swap out the page frame associated with the data transfer

    - To avoid this inefficiency buffering can be used.

   - No buffer the os directly accesses the device when it needs to.

  - Buffering s where we introduce additional memory space to reduce memory inefficiencies
    - Input opeartions take in more than is requested.

    - Output operations are actually completed some time after the request is made when it is convenient
  - Transfers are to/from an area of system memory known as IO buffers rather than directly to/from the process memory space.

** Single buffer
- OS assigns a buffer in main memory for an IO request

  - Now the process can be processing one block of data while the other is being read in and the OS can swap out any page frame belonging to the process without
    interfering with any IO operation.

** With buffering

- Input operations take in more than is requested so it is more likely that what a process requests is already in a RAM buffer -> less time blocked

  - Output operations are actually completed some time after the request is made

** Double buffer
- Use two sys buffers instead of one
  - Extra buffer allows process to access one buffer while the OS handles another IO operation in the other.
  - A process can transfer data to or from one buffer while the OS empties or fills  the other buffer.
    - Also known as buffer swapping.
** Circular buffer

- Two or more buffers
  - Each buffer is one unit in a circular buffer
    - Used when IO operations must keep up with processes

** Utility of buffering

- Technique smoothes out peaks in IO demand
  - With enough demand eventually all buffers become full, advantage is lost.

- When there is a variety of IO and process activities to service, buffering can increase efficiency of the OS.
    
